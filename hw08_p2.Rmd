---
title: "HW08, pt 2:"
author: "Julia Du"
date: "`r lubridate::today()`"
output: 
  github_document:
    toc: true
---

## Load necessary libraries

```{r, message = FALSE}
library(tidyverse)
library(stringr)
library(jsonlite)
library(httr)

library(rvest)

nyt_api <- getOption("nyt_semantics_key")
guardian_api <- getOption("guardian_key")

theme_set(theme_minimal())
```

keep in mind you'll need to have your own API key for both NYT (Semantics API) & Guardian API. store it in .Rprofile w/ format of options(keyname = "actualkeycode").

## Overview
compare coverage of BLM this past yr geographically?

track coverage of gay marriage over time? since maybe 2000?

reference: https://open-platform.theguardian.com/documentation/tag

```{r}
guard_equal <- GET(
  url = "https://content.guardianapis.com/search?", 
  query = list(`q` = "equal-marriage", 
               `api-key` = guardian_api)
  )


guardjson <- content(guard_equal, as = "parsed", type = "application/json") %>% 
  as_tibble()

jsonlite::fromJSON(guardjson)

guardjson %>%
  unnest_auto(response)
#%>%
  hoist(9)


guard_equal 
```

## 

```{r}


nyt_trump <- GET(
  url = "http://api.nytimes.com/svc/semantic/v2/concept", 
  query = list(`nytd_per` = "Trump, Donald", 
               `api-key` = nyt_api)
  )

nyt_trump$url
nyt_response <- content(nyt_trump, "text")

nyt_response_df <- fromJSON(nyt_response, simplifyDataFrame = TRUE, flatten = TRUE)

str(response_df, max.level = 2)
```

```{r}
base.url <- "http://api.nytimes.com/svc/search/v2/articlesearch.json"
search_term <- "'John Mearsheimer'"

r <- GET(base.url, 
         query = list(`q` = search_term,
                      `api-key` = nyt_api))

bs <- content(r, "text")
str_sub(bs, 1, 1000)

bs_df <- fromJSON(bs, simplifyDataFrame = TRUE, flatten = TRUE)

# Inspect the dataframe
str(bs_df, max.level = 2)
```





```{r asoiaf}
stark <- GET(
  url = "https://www.anapioficeandfire.com/api/houses",
  query = list(name = "House Stark")
  )

stark$url



asoiaf_houses <- function(housename){
  response <- GET(url = "https://anapioficeandfire.com/api/houses",
                  query = list(name = housename))
  
  response_df <- content(response) %>%
    as_tibble()
  
}

house <- c("Stark", "Lannister", "Targaryen")
asoiaf_houses("Stark")
```

Rachelle Terman - NYT

## pivot to scraping lol
```{r}
# use SelectorGadget
pterry <- read_html("https://www.goodreads.com/author/show/1654.Terry_Pratchett")

pterry_quotes <- read_html("https://www.goodreads.com/author/quotes/1654.Terry_Pratchett")

quotes <- html_nodes(pterry_quotes, ".quoteText")

name <- html_text(quotes) %>%
  str_trim(side = "both") 

gsub("CDATA.*", "", name)
#%>%
#  str_remove_all(".CDATA*")

#str_extract


quotes1 <-html_nodes(pterry_quotes, ".authorOrTitle")

html_text(quotes1) %>%
  str_trim(side = "both")


# this works
pterry_tags <- html_nodes(pterry_quotes, ".left")

test <- pterry_tags %>%
  html_text() #%>%
#  str_trim(side = "both") 

test %>%
  str_replace_all(pattern = "tags:", "") %>%
  str_replace_all(pattern = "\n       ", " ") %>%
  str_trim(side = "both")

pterry_text <- html_nodes(pterry_quotes, "span.authorOrTitle , .quoteText")

try <- pterry_text %>%
  html_text()
try %>%
  str_replace_all(pattern = "")

#separate
```


```{r books}
books <- read_html("http://books.toscrape.com/")

books_titles_nodes <- html_nodes(books, ".product_pod a ")

titles_df <- books_titles_nodes %>%
  html_text() %>%
  as_tibble() %>%
  filter(!(value=="")) %>%
  rename(title = value)

books_prices_nodes <- html_nodes(books, ".price_color")

prices_df <- books_prices_nodes %>%
  html_text() %>%
  as_tibble() %>%
  filter(!(value=="")) %>%
  rename(price = value)

titles_df %>%
  bind_cols(prices_df)
```

```{r mangaupdates}
library(tidyverse)
library(rvest)

manga_p1 <- read_html("https://www.mangaupdates.com/stats.html")

manga_p1_nodes <- html_nodes(manga_p1, ".text-truncate span , .text-truncate u, #main_content .text.text-center")

manga_vec <- manga_p1_nodes %>%
  html_text() %>%
  purrr::discard(.p = ~stringr::str_detect(.x,"Rank"))
    
wip_manga <- split(manga_vec, ceiling(seq_along(manga_vec)/3)) %>%
  as_tibble()

almost_manga_df <- wip_manga %>%
  mutate(placeholder = c("rank", "title", "genre"), .before = 1) %>% 
  #could stop here
  mutate(row = row_number()) %>%
  filter(!row == "1") %>%
  pivot_longer(c(`1`:`25`), names_to = "rank", values_to = "values") %>%
  pivot_wider(names_from = placeholder, values_from = values) 

almost_manga_top <- almost_manga_df %>%
  slice_head(n = 25)

almost_manga_bottom <- almost_manga_df %>%
  slice_tail(n = 25)

neat_manga <- left_join(almost_manga_top, almost_manga_bottom, by = "rank") %>%
  select(-c(row.x, genre.x, title.y, row.y)) %>%
  rename(title = title.x, genre = genre.y)

neat_manga
```

```{r manga_multiple}
multiple_manga <- function(url, pg){
  manga <- read_html(url)

manga_nodes <- html_nodes(manga, ".text-truncate span , .text-truncate u, #main_content .text.text-center")

manga_vec <- manga_nodes %>%
  html_text() %>%
  purrr::discard(.p = ~stringr::str_detect(.x,"Rank"))
    
wip_manga <- split(manga_vec, ceiling(seq_along(manga_vec)/3)) %>%
  as_tibble()

almost_manga_df <- wip_manga %>%
  mutate(placeholder = c("rank", "title", "genre"), .before = 1) %>% 
  #could stop here
  mutate(row = row_number()) %>%
  filter(!row == "1") %>%
  pivot_longer(c(`1`:`25`), names_to = "rank", values_to = "values") %>%
  pivot_wider(names_from = placeholder, values_from = values) 

almost_manga_top <- almost_manga_df %>%
  slice_head(n = 25)

almost_manga_bottom <- almost_manga_df %>%
  slice_tail(n = 25)

neat_manga <- left_join(almost_manga_top, almost_manga_bottom, by = "rank") %>%
  select(-c(row.x, genre.x, title.y, row.y)) %>%
  rename(title = title.x, genre = genre.y) %>%
  mutate(rank = as.numeric(rank)) %>%
  mutate(rank = rank + 25*(pg-1))

neat_manga
}

multiple_manga("https://www.mangaupdates.com/stats.html?page=2&", 2)

manga_urls <- c("https://www.mangaupdates.com/stats.html?page=1&", "https://www.mangaupdates.com/stats.html?page=2&", "https://www.mangaupdates.com/stats.html?page=3&")
manga_pgs <- c(1, 2, 3)

manga_75 <- map2_dfr(.x = manga_urls, .y = manga_pgs, .f = multiple_manga)
```



```{r viz_manga}
# function to count how many mangas belong to certain genre
genre_count <- function(genre_string){
  manga_75 %>%
    filter(str_detect(genre, genre_string)) %>%
    count() %>%
    mutate(genre = genre_string)
}

genres_of_interest <- c("Action", "Comedy", "Drama", "Fantasy", "Romance")

map_dfr(genres_of_interest, genre_count) %>%
  ggplot(mapping = aes(x = genre, y = n, fill = genre, label = n)) +
  geom_col() +
  labs(title = "Common genres in 75 top-ranked mangas", subtitle = "As of Mar. 2021", x = "Genre", y = "Number of mangas", fill = "", caption = "Source: mangaupdates.com") +
  geom_label() +
  theme(legend.position = "none")



# have to create new functions because unable to map input vectors of diff lengths 
#shoujo 
shoujo_genre_count <- function(genre_string){
  length <- manga_75 %>%
  filter(str_detect(genre, "Shoujo")) %>%
  count() %>%
  pull()
  
  manga_75 %>%
    filter(str_detect(genre, "Shoujo")) %>%
    filter(str_detect(genre, genre_string)) %>%
    count() %>%
    mutate(genre = genre_string, percent = n/length, audience = "shoujo")
  }

shoujo_df <- map_dfr(genres_of_interest, shoujo_genre_count)

shounen_genre_count <- function(genre_string){
  length <- manga_75 %>%
  filter(str_detect(genre, "Shounen")) %>%
  count() %>%
  pull()
  
  manga_75 %>%
    filter(str_detect(genre, "Shounen")) %>%
    filter(str_detect(genre, genre_string)) %>%
    count() %>%
    mutate(genre = genre_string, percent = n/length, audience = "shounen")
  }

shounen_df <- map_dfr(genres_of_interest, shounen_genre_count)

shoujo_df %>%
  bind_rows(shounen_df) %>% 
  ggplot(aes(x = genre, y = percent, fill = audience)) +
  geom_col(position = position_dodge2(width = 0.9, preserve = "single")) +
  labs(title = "Top genres among popular shoujo and shounen manga", subtitle = "As of Mar. 2021", x = "Genre", y = "Percentage of audience-specific manga", fill = "Audience", caption = "Source: mangaupdates.com") +
  scale_y_continuous(labels = scales::percent) +
  theme(legend.position = "bottom")

```


